# Prozesse

Prozesse sind das zentrale Konzept in jedem Betriebssystem.

- Prozess = Programm in AusfÃ¼hrung
- modellieren NebenlÃ¤ufigkeit
  - (Quasi-)ParallelitÃ¤t
  - Multiprogrammierung

## Prozessmodell

> Das Betriebssystem ist als Menge von (sequentiellen) Prozessen organisiert!

Jeder Prozess umfasst eine virtuelle CPU mit eigenem Adressraum

âž¡ BefehlszÃ¤hler, Registerinhalte, Belegung von Variablen, ...

Da jeder Prozess einen eigenen BefehlszÃ¤hler hat, dÃ¼rfen keine Annahmen Ã¼ber den Zeitablauf getroffen werden.

### Unterschied Programm und Prozess

| Programm                     | Prozess               |
| ---------------------------- | --------------------- |
| Rezept mit allen Anweisungen | AktivitÃ¤t des Backens |

Wird ein Programm 2x gestartet, ergibt das 2 Prozesse

## Prozesserzeugung

- Durch das Betriebssystem:
  - Initialisierung (als Hintergrundprozess)
  - Durch einen anderen Prozess (Systemaufruf)

Bsp.: Linux starten:
![Bsp.: Start von Linux Prozess init](./img/prozess_start_linux.png)

## Beziehungen zwischen Prozessen

Eltern-Kind-Beziehung

âž¡ Prozess-Familien bzw. Prozess-Hierarchien

- UNIX
  - Signale werden an alle Mitglieder der Familie verschickt
  - Prozesse entscheiden selbst, wie auf Signal reagiert werden soll
- Windows
  - Kein Konzept der Prozesshierarchie
  - alle Prozesse sind gleichwertig
    - Beziehungen werden durch Tokens (Handle) gesteuert
    - Enterbung durch Weitergabe von Handles mÃ¶glich

## Prozessbeendigung

- Normales Beenden (freiwillig)
  - Wenn Aufgabe erledigt ist (exit / exitProcess)
- Beenden aufgrund eines Fehlers (freiwillig)
  - Prozess stellt einen Fehler fest, der nicht vom Programm verursacht wurde (bspw. Datendatei nicht vorhanden)
- Beenden aufgrund eines schwerwiegenden Fehlers (unfreiwillig)
  - Prozess selbst verursacht einen Fehler
  - AusfÃ¼hren eines unzulÃ¤ssigen Befehls
  - Zugriff auf ungÃ¼ltige Speicheradresse
- Beenden durch anderen Prozess (unfreiwillig)
  - (kill / TerminateProcess)

## Prozess-Zustandsmodell

![Zustandsmodell mit Ready, Running, Blocked](img/prozesszustaende.jpg)
ÃœbergÃ¤nge werden vom Betriebssystem (Scheduler) verwaltet

## Scheduler

... verwaltet die Prozesse und ist die unterste Schicht des Betriebssystems

### Aufgaben

- Unterbrechungen (Interrupts) behandeln
- Starten und Stoppen von Prozessen
- Warteschlange fÃ¼r Prozesse

### Warteschlangenmodell

![Zustandsmodell mit Warteschlangen modelliert](img/scheduler_warteschlange_modell.png)

## Modell fÃ¼r Prozessverwaltung

Prozesstabelle:

- Ein Eintrag pro Prozess (Prozesskontrollblock (PCB))
- PCB beinhaltet alle Prozessinformationen
  - Prozessverwaltung:
    - Register, BefehlszÃ¤hler, Stack, Program status word (PSW)
    - Prozessidentifikation (PID, Eltern-PID, UserID)
    - Zustandsinformationen (PrioritÃ¤t, verbrauchte CPU-Zeit, Signale, ...)
  - Speicherverwaltung
    - Pointer auf Textsegment
    - Pointer auf Datensegment
    - Pointer auf Stacksegment
  - Dateiverwaltung
    - Wurzelverzeichnis
    - Arbeitsverzeichnis
    - Offene Dateien
    - Benutzer-ID
    - Gruppen-ID

## Prozesswechsel (Bsp. E/A)

1. Sichern des BefehlszÃ¤hlers, Prozessorstatus, ...
   - Prozess auf "Blocked" setzen
2. Ursache der Unterbrechung ermitteln
3. Ereignis (z.B. Ende der E/A) entsprechend behandeln
   - Blockierte Threads auf "Ready" setzen
4. Sprung zum Scheduler
   - Entscheidet, welcher Prozess als nÃ¤chstes lÃ¤uft

Durch Multiprogrammierung erreichen wir eine verbesserte CPU-Auslastung. Wenn auf E/A gewartet wird, kann ein anderer Prozess in dieser Zeit auf die CPU.

# Threads

Bisher:

- Jeder Prozess hat einen _eigenen Adressraum_
- nur _einen AusfÃ¼hrungsfaden_
- Dadurch kein Zugriff auf den gleichen Zugriff mÃ¶glich.

LÃ¶sung: Threads

- Erweitertes Prozessmodell
  - mehrere AusfÃ¼hrungsfÃ¤den mit _gleichem Addressraum_
  - AusfÃ¼hrung im Benutzermodus mÃ¶glich
  - Erstellung ist 10-100 mal schneller als Prozesse
- Ressourcen-BÃ¼ndelung
  - Adressraum, geÃ¶ffnete Dateien, Signale, Kindprozesse, ...
- AusfÃ¼hrung von Prozessen
  - BefehlszÃ¤hler, Register, Stack, ...
  - Mehrere Threads sind in einem Prozess mÃ¶glich

![Threads und Prozesse](img/threads_prozesse.png)

## Thread-Verwaltung

Threads werden in einer Thread-Tabelle verwaltet. Dazu gehÃ¶ren:

- Thread-ID
- BefehlszÃ¤hler, Register, Stack, Zustand

Jeder Thread hat einen eigenen Stack, aber gemeinsamen Adressraum.

### Lebenszyklus eines Threads

1. Erzeugung
   - Prozess erzeugt Thread (create)
   - Thread lÃ¤uft im Adressraum des erzeugenden Prozesses
2. Beendigung
   - Nach Beendigung der Aufgabe oder Fehler (exit)
3. Synchronisation
   - Threads kÃ¶nnen aufeinander warten (join)
4. Freiwilliger Verzicht
   - Thread gibt CPU frei (yield)

Der Thread-Scheduler kann im Kernel oder im Benutzermodus laufen:
![Thread-Scheduler](img/thread_scheduler.png)

|        | Benutzermodus                                            | Kernmodus                                           |
| ------ | -------------------------------------------------------- | --------------------------------------------------- |
| Pro    | schneller Wechsel                                        | Kein Laufzeitproblem                                |
|        | Angepasster Scheduler                                    | Effizienter Umgang mit blockierenden Systemaufrufen |
|        |                                                          |                                                     |
| Contra | Umgang mit blockierenden Systemaufrufen                  | HÃ¶here Kosten bei Threadwechsel                     |
|        | Ein Thread kann den gesamten Prozess blockieren          | Umngang mit Signalen                                |
|        | Threads sollen Programme ermÃ¶glichen, die oft blockieren |                                                     |

ðŸ’¡ Threads werden meist im Kernmodus realisiert!

## Threadwechsel

... erfolgt immer, wenn BS die Kontrolle erhÃ¤lt:

- Systemaufrufen
- Interrupts
- Ausnahmebehandlungen

Scheduler des BS entscheidet, welcher Thread als nÃ¤chstes lÃ¤uft.

# Vergleich Prozesse und Threads

- Prozess ist eine Einheit der Ressourcenverwaltung, Schutzeinheit
  - Adressraum, geÃ¶ffnete Dateien, Signale, PrioritÃ¤ten, ...
- Thread ist eine Einheit der Prozessorzuteilung
  - BefehlszÃ¤hler, Register, Stack, Zustand, ...

âž¡ mehrere Threads pro Prozess mÃ¶glich

# Interprozess-Kommunikation

Prozesse nutzen gemeinsame Ressourcen, haben aber getrennte AdressrÃ¤ume.

- unbewusst (Wettstreit)
- bewusst (Kooperation)
- Prozesse kÃ¶nnen sich kennen (Kommunikation)

Daher ist eine strukturierte Kommunikation notwendig.

## Problemkreise

- Informationen von einem Prozess an anderen weiterleiten (strukturiert)
- Vermeiden des gleichzeitigen Zugriffs auf gemeinsame Ressourcen
- Ablauf von Prozessen organisieren, wenn AbhÃ¤ngigkeiten vorliegen

## Race Conditions (Wettstreit)

- Prozesse nutzen gemeinsamen Speicher (Festplatte, Arbeitsspeicher, Drucker, etc.)
- Endergebnis hÃ¤ngt vom Ablauf ab
- Unbedingt vermeiden!

### Wie zu vermeiden?

- Zu einem Zeitpunkt darf nur jeweils einem Prozess der Zugriff erlaubt werden
- Synchronisation notwendig!
  - Sperrsynchronisation (AusfÃ¼hrung in beliebiger Reihenfolge)
  - Reihenfolgesynchronisation (in fester Reihenfolge)

# Wechselseitiger Ausschluss

- Kritische Regionen/Abschnitte
- Teile des Programmes, der Zugriff auf gemeinsam genutzte Ressourcen (kritische Ressourcen) enthÃ¤lt

## Bedingungen fÃ¼r wechselseitigen Ausschluss

1. Keine zwei Prozesse sind gleichzeitig in kritischen Regionen
2. Keine Annahmen Ã¼ber Geschwindigkeit und Anzahl der CPU
3. Kein Prozess, der auÃŸerhalb der kritischen Regionen lÃ¤uft, darf andere Prozesse blockieren
4. Kein Prozess soll ewig warten, um in seine kritische Region einzutreten

![Wechselseitiger Ausschluss](img/wechselseitiger_ausschluss.png)

## MÃ¶gliche Verfahren fÃ¼r wechselseitigen Ausschluss

### Ansatz 1: Interrupts ausschalten

- Prozesswechsel erfolgen durch Interrupt
- Probleme:
  - Funktioniert nur bei Ein-Prozessor-Rechnern
  - E/A ist blockiert
  - Ein Prozess im Benutzerraum Ã¼bernimmt Kontrolle Ã¼ber BS
    - was passiert, wenn Interrupts nicht mehr eingeschaltet werden?

### Ansatz 2: Sperrvariablen

- Variable belegt zeigt an, ob kritischer Abschnitt belegt ist

```c
// Prozess 1
{
  while(belegt);    //begin_region()
  belegt = true;    //begin_region()
  // kritischer abschnitt
  belegt = false;   //end_region()
}

// Prozess 2
{
  while(belegt);    //begin_region()
  belegt = true;    //begin_region()
  // kritischer abschnitt
  belegt = false;   //end_region()
}
```

- Problem: Verhindert race condition nicht sicher
  1. Prozesse fÃ¼hren begin_region() gleichzeitig aus
  2. belegt wird von beiden Prozessen auf true gesetzt
  3. Beide Prozesse betreten kritischen Abschnitt

### Ansatz 3: Strikter Wechsel

- Variable `turn` gibt an wer an der Reihe ist

```c
// Prozess 0
{
  while(turn != 0);    //begin_region()
  // kritischer abschnitt
  turn = 2;            //end_region()
}

// Prozess 1
{
  while(turn != 1);    //begin_region()
  // kritischer abschnitt
  turn = 1;            //end_region()
}
```

- Problem: Verletzt die Anforderungen 3 und 4 der Bedingungen fÃ¼r wechselseitigen Ausschluss
  - âž¡ Prozesse mÃ¼ssen abwechselnd in kritischen Abschnitt eintreten

### Ansatz 4: LÃ¶sung von Peterson

- Verbindung von Abwechseln und Sperrvariable

```c
// Prozess 0
{
  interested[0] = true;                 //begin_region()
  turn = 1;                             //begin_region()
  while(interested[1] && (turn == 1));    //begin_region()
  // kritischer abschnitt
  interested[0] = false;                //end_region()
}

// Prozess 1
{
  interested[1] = true;                 //begin_region()
  turn = 0;                             //begin_region()
  while(interested[0] && turn == 0);    //begin_region()
  // kritischer abschnitt
  interested[1] = false;                //end_region()
}
```

- Dies verhindert eine Verklemmung und race condition
- Jeder Prozess bekommt die Chance den kritischen Abschnitt zu betreten

**Frage: funktioniert die LÃ¶sung auch bei Mehrprozessorsystemen?**

- Problem:
  - Abfragen und Ã„ndern einer Variablen sind zwei Schritte
- LÃ¶sung:
  - Atomare ReadModifiyWrite Operation der CPU
    - TSL = TestSetLock
    - Bei der AusfÃ¼hrung wird der Speicherbus gesperrt

**âž¡ Ja, aber HardwareunterstÃ¼tzung ist notwendig!**

Effizienz:

- Busy-Waiting âž¡ Prozessor wird blockiert
- Prozess belegt CPU wÃ¤hrend des Wartens
- Ãœberrauschungseffekt bei unterschiedlichen PrioritÃ¤ten
  - Prozess mit niedrigerer PrioritÃ¤t kann Prozess mit hÃ¶herer PrioritÃ¤t blockieren
- ABER: Busy-Wait kann dennoch notwendig sein!

## Erzeuger-Verbraucher-Problem

Verallgemeinert:

- Erzeuger legen Dinge in Puffer
- Verbraucher nehmen Dinge aus Puffer

Es ist eine Synchronisation zwischen Erzeuger und Verbraucher notwendig:

- Erzeuger wartet, wenn Puffer voll ist
- Verbraucher wartet, wenn Puffer leer ist

Vermeidung von "busy wait" durch blockierende Systemaufrufe:

- sleep() -> Veranlasst den Aufrufer zu blockieren
- wakeup(pid) -> hebt die Blockierung von Prozess pid auf

- Erzeuger:
  - wird blockiert, falls Puffer voll ist (geht schlafen)
  - wird vom Verbraucher geweckt, wenn Puffer leer
- Verbraucher:
  - Wird blockiert, wenn der Puffer leer ist
  - Wird vom Erzeuger geweckt, wenn der Puffer voll ist

### Race Condition

Beispiel Erzeuger-Verbraucher:

```c
Producer ()
{
	while(TRUE) {
		Item = produce_item();
		if (count == N)
			sleep();
		insert_item(Item); // kritische Stelle
		count++;           // kritische Stelle
		if (count == 1)
			wakeup(consumer);
	}
}

Consumer()
{
	while(TRUE) {
		if (count == 0)
			sleep();
		Item = remove_item(Item); // kritische Stelle
		count--                   // kritische Stelle
		if (count == N-1)
			wakeup(producer);
		consume(Item);
	}
}
```

1. Puffer ist leer (`count = 0`) und Verbraucher analysiert `count`
2. der Scheduler wechselt und der Erzeuger schreibt was in den Puffer und erkennt, dass das count nun 1 ist und weckt den Consumer
3. Der Consumer lÃ¤uft weiter und wird beim nÃ¤chsten Aufruf schlafen gehen
   -> Ein Weckruf geht verloren

# Semaphoren

... sind allgemeine Synchronisationskonstrukte fÃ¼r wechselseitigen Ausschluss und fÃ¼r Reihenfolgensynchronisation

- Ganzzahlige Variable
  - **0 ->kein Weckruf**
  - **>0 -> ein oder mehrere Weckrufe**

Bedeutung des ZÃ¤hlers:

- ZÃ¤hler >= 0:
  - Anzahl freier Ressourcen
  - bspw. Flaschen im Automat
- ZÃ¤hler < 0:
  - Anzahl der wartenden Prozesse
  - bspw. durstige Studierende

2 **atomare** Funktionen notwendig:

- `down()`
  - Verallgemeinerung von `sleep()`

```c
if (Semaphor > 0) Semaphor --;
else if (Semaphor == 0) block(this_process);
```

- `up()`
  - Verallgemeinerung von `wakeup()`

```c
Semaphor++;
if (Semaphor <= 0) up(blocked_process);
```

## Implementierung

```c
Struct Semaphor {
	int count;
	Queue queue;
}

void down(Semaphor &s) {
	s.count--;
	if (s.count < 0) {
		// Prozess in s.queue ablegen;
		// Prozess blockieren;
	}
}

void up(Semaphor &s) {
	s.count++;
	if (s.count <= 0) {
		// Prozes aus s.queue holen;
		// Prozess auf READY setzen;
	}
}
```

- Es sind nur diese beiden Operationen erlaubt.
- Operationen _mÃ¼ssen_ atomar sein

## Mutex

... ist Anwendung von Semaphoren auf wechselseitigen Ausschluss

Mutex markiert einen kritischen Abschnitt/ Ressource/ ...

Mutex.ZÃ¤hler = 1
->BinÃ¤res Semaphor

```c
// Prozess 1
{
  down(mutex);    //begin_region()
  // kritischer abschnitt
  up(mutex);   //end_region()
}

// Prozess 2
{
  down(mutex);    //begin_region()
  // kritischer abschnitt
  up(mutex);   //end_region()
}
```

## Anwendung auf Erzeuger-Verbraucher-Problem

Anforderungen:

1. Nur ein Prozess darf auf den Puffer zugreifen
2. Aus dem leeren Puffer darf nichts entfernt werden
3. In den vollen Puffer darf nichts eingefÃ¼gt werden

LÃ¶sung:

1. Wechselseitiger Ausschluss (Mutex)
2. Semaphore full
   - wird mit 0 initialisiert
3. Semaphore empty
   - Wird mit **N=PuffergrÃ¶ÃŸe** initialisiert

Dadurch haben wir wechselseitigen Ausschluss und eine Reihenfolgesynchronisation

```c
Semaphor mutex = 1; // wechselseitiger Ausschluss
Semaphor full = 0;  // verhindert Entfernen aus leerem Puffer
Semaphor empty = N; // verhindert Schreiben in vollen Puffer

void producer() {
	while (TRUE) {
		item = produce_item();
		down(&empty);
		down(&mutex);
		insert_item(item);
		up(&mutex);
		up(&full);
	}
}

void consumer() {
	while (TRUE) {
		down(&full);
		down(&mutex);
		item = remove_item();
		up(&mutex);
		up(&empty);
	}
}
```

âž¡ **Daumemregel: Eine Semaphore fÃ¼r jede Randbedingung (Constraint)**

ðŸ’¡Reihenfolge ist wichtig!

# Monitor

- Programmierung von Semaphoren ist schwierig
  - Reihenfolge der up/down-Operationen wichtig
  - Synchronisation Ã¼ber das gesamte Programm verteilt

MÃ¶gliche LÃ¶sung: Monitore

- Sammlung von Prozeduren, Variablen, Datenstrukturen
- Zugriff auf Daten nur Ã¼ber Monitor-Prozeduren
- Alle Prozeduren stehen unter wechselseitigem Ausschluss
  - nur jeweils ein Prozess kann den Monitor benutzen
  - nur eine Prozedur des Monitor kann ausgefÃ¼hrt werden
- Realisierung Ã¼ber Compiler

ðŸ’¡In Java: "`sychronized`" garantiert, dass nur eine Methode des Objekts ausgefÃ¼hrt wird.

## Realisierung

- Mutex fÃ¼r wechselseitigen Ausschluss
- FÃ¼r Reihenfolgensynchronisation:
  - Zustandsvariable
  - Zwei Operationen:
    - `wait()`: Blockieren des aufrufenden Prozesses
    - `signal()`: Aufwecken blockierter Prozesse

![[monitor_realisierung.png]]

## Eigenschaften von Monitoren

- Es kann immer nur ein Prozess im Monitor aktiv sein!
- Zentrale Idee: Prozess kann auch innerhalb der kritischen Region schlafen gehen, da der Lock mit dem schlafen gehen freigegeben wird
  - Unterschied zu Semaphore: kann nicht in krit. Reg. warten
- Monitor-Realisierung braucht:
  - Mutex
  - Zustandsvariablen

### Vorteile und Nachteile von Monitoren

| Pro                                   | Contra                                                                                          |
| ------------------------------------- | ----------------------------------------------------------------------------------------------- |
| Weniger FehleranfÃ¤llig als Semaphoren | Da Monitore ein Pattern sind, muss der Kompiler damit umgehen kÃ¶nnen. C alleine kann das nicht. |
|                                       | Monitore eignen sich nicht fÃ¼r verteilte Systeme                                                |

âž¡ Austausch von Nachrichten in Verteilten Systemen

# Nachrichtenaustausch

(message passing)

## Motivation:

- Bisher: speicherbasierte Kommunikation
  - Ã¼ber gemeinsamen Speicher
  - Synchronisation muss explizit programmiert werden
- Nachrichtenbasierte Kommunikation:
  - Senden/Empfangen von Nachrichten (Ã¼ber das BS)
  - Ã¼ber Rechnergrenzen hinweg mÃ¶glich
  - implizite Synchronisation

## Primitive

1. `send(Ziel, Nachricht)`
   - Versenden einer Nachricht (Ã¤hnlich wie `up()`)
2. `receive(Quelle, Nachricht)`
   - Empfang einer Nachricht (Ã¤hnlich wie `down()`) -> Blockieren, bis Nachricht vorhanden

### Besonderheiten

- Nachrichten werden bestÃ¤tigt (Ack) -> Verlust von Nachrichten absichern
- Authentifizierung in verteilten Systemen
- Lokal ist Nachrichtenaustausch immer langsamer als Semaphoren

# Deadlocks/Verklemmungen

Next:
[Scheduling und Deadlocks](03-SchedulingDeadlocks.md)
